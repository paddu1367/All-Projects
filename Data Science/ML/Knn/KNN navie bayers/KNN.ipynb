{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vv_zPafJd5o3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uzyyh7qBwi6n"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kBm52gI6eHDo"
   },
   "outputs": [],
   "source": [
    "def counter(x):\n",
    "    one_count = 0\n",
    "    zero_count = 0\n",
    "    for i in x:\n",
    "        if i==0:\n",
    "            zero_count+=1\n",
    "        elif i==1:\n",
    "            one_count+=1\n",
    "        else:\n",
    "            return 'Invalid type :'+i\n",
    "    if zero_count >one_count:\n",
    "        return 0 \n",
    "    elif one_count>zero_count:\n",
    "        return 1\n",
    "        \n",
    "class Knn:\n",
    "    def __init__(self,n_neighbors,metrics = 'Euclidean'):\n",
    "        #class initilization\n",
    "        self.n_neighbors = n_neighbors\n",
    "        if(metrics=='Euclidean'):\n",
    "            self.metrics =self.euclidean\n",
    "        elif(metrics=='Manhattan'):\n",
    "            self.metrics = self.manhattan\n",
    "        elif(metrics=='Minkowski'):\n",
    "            self.metrics = self.minkowski\n",
    "    def euclidean(self,x1,x2):\n",
    "        #to calculate Euclidean distance\n",
    "        if(x1.shape==x2.shape):\n",
    "            distance = sum((px - qx) ** 2.0 for px, qx in zip(x1, x2))\n",
    "            return math.sqrt(distance)\n",
    "        else:\n",
    "            return -1\n",
    "    def manhattan(self,x1,x2):\n",
    "        if(x1.shape==x2.shape):\n",
    "            distance = sum((px - qx) for px, qx in zip(x1, x2))\n",
    "            return abs(distance)\n",
    "        else:\n",
    "            return -1\n",
    "    def minkowski(self,x1,x2):\n",
    "        if(x1.shape==x2.shape):\n",
    "            distance = sum((px - qx) ** 3.0 for px, qx in zip(x1, x2))\n",
    "            return np.cbrt(distance)\n",
    "        else:\n",
    "            return -1\n",
    "    def fit(self,x_train,y_train):\n",
    "        self.x_train=x_train\n",
    "        self.y_train=y_train\n",
    "    def predict(self,x_test):\n",
    "        y_predict = []\n",
    "        y_train = self.y_train\n",
    "        for x in x_test:\n",
    "            distance = []\n",
    "            for x_train in self.x_train:\n",
    "                dist = self.metrics(x,x_train)\n",
    "                distance.append(dist)\n",
    "            distance = np.array(distance).reshape(len(self.x_train),1)\n",
    "            np_dists = np.hstack([distance,y_train])\n",
    "            # Sort distances, and n closest points\n",
    "            np_dists = np_dists[np_dists[:,0].argsort()][:self.n_neighbors]\n",
    "            # Create counter object to track the labels of k closest neighbors\n",
    "            # Get Most common label of all the nearest neighbors\n",
    "            prediction = counter(np_dists[:,1])\n",
    "            y_predict.append(prediction)\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIrxMVuHoIE9"
   },
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "COT6vviFwqXR"
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        self.means = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self.var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self.priors =  np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        # calculating the mean, variance and prior P(H) for each class\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_class=[]\n",
    "            for j in range(len(X)):\n",
    "                if y[j]==c:\n",
    "                    X_class.append(X[j])\n",
    "            X_class = np.array(X_class)\n",
    "            self.means[i, :] = X_class.mean(axis=0)\n",
    "            self.var[i, :] = X_class.var(axis=0)\n",
    "            self.priors[i] = X_class.shape[0] / float(n_samples)\n",
    "\n",
    "    # calculating the likelihood, P(E|H)\n",
    "    def likelihood(self, class_idx, x):\n",
    "        mean = self.means[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        num = np.exp(- (x-mean)**2 / (2 * var))\n",
    "        denom = np.sqrt(2 * np.pi * var)\n",
    "        return num / denom\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self.classify(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def classify(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculating posterior probability for each class\n",
    "        for i, c in enumerate(self.classes):\n",
    "            posteriors.append(np.log(self.priors[i])+np.sum(np.log(self.likelihood(i, x))))\n",
    "            \n",
    "        # return the class with highest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F5WpDR6LoKZi"
   },
   "outputs": [],
   "source": [
    "def clean_data(row):\n",
    "    return row.replace('(', '').replace('W','1').replace('M','0').replace(')', '').replace(' ', '').strip().split(',')\n",
    "def readFile(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "        clean = list(map(clean_data, data))\n",
    "        file.close()\n",
    "    input_np = np.array(clean)\n",
    "    return input_np\n",
    "\n",
    "training = './dataset/1a-training.txt'\n",
    "test = './dataset/1a-test.txt'\n",
    "\n",
    "train_np = readFile(training).astype(float)\n",
    "test_np = readFile(test).astype(float)\n",
    "x_train =train_np[: , 0:3]\n",
    "y_train = train_np[:, 3].reshape(len(x_train),1)\n",
    "x_test = test_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEvGGS6BShNP"
   },
   "source": [
    "KNN implementation on Traning and testing data with k=1,3,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMVD91BR7ITA",
    "outputId": "2041e000-9550-492d-8223-df6a948505df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN for k=1 : [1, 1, 1, 1]\n",
      "Naive Bayes predction : [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "k1 = Knn(1,'Euclidean')\n",
    "nb = GaussianNaiveBayes()\n",
    "nb.fit(x_train,y_train)\n",
    "k1.fit(x_train,y_train)\n",
    "print('KNN for k=1 :',k1.predict(x_test))\n",
    "print('Naive Bayes predction :', nb.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIwtavKiSHz_",
    "outputId": "c5ba3a72-de65-4858-dc76-29bbaf81e5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN for k=3 : [1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "k3 = Knn(3,'Manhattan')\n",
    "k3.fit(x_train,y_train)\n",
    "print('KNN for k=3 :',k3.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isO0waexSTA_",
    "outputId": "18edcffb-5c2f-4ac2-c92b-bee93994289d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN for k=7 : [1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "k7 = Knn(7,'Euclidean')\n",
    "k7.fit(x_train,y_train)\n",
    "print('KNN for k=7 :',k7.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4fTn2b-SuXY"
   },
   "source": [
    "Leave one-out Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LQOIobZLS4_G"
   },
   "outputs": [],
   "source": [
    "large_data = './dataset/1c-data.txt'\n",
    "inpu=readFile(large_data).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDA9NUIadzje",
    "outputId": "880f40cf-222e-43b7-f6c7-e2762d7b8deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3) (120, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train =inpu[: , 0:3]\n",
    "y_train = inpu[:, 3].reshape(len(x_train),1)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0r9bFUDHeVPy"
   },
   "outputs": [],
   "source": [
    "def leave_out(model,x_train,y_train):\n",
    "    count =0\n",
    "    for i in range(len(x_train)):\n",
    "        x_test = np.array(x_train[i]).reshape(1,x_train.shape[1])\n",
    "        y_test = np.array(y_train[i])\n",
    "        x_train_i= x_train[0:i, :]\n",
    "        y_train_i = y_train[0:i,:]\n",
    "        x_train_j = x_train[i+1:,:]\n",
    "        y_train_j = y_train[i+1:,:]\n",
    "        x_train_input = np.vstack((x_train_i,x_train_j))\n",
    "        y_train_input = np.vstack((y_train_i,y_train_j))\n",
    "\n",
    "        model.fit(x_train_input,y_train_input)\n",
    "        if(model.predict(x_test)==y_test):\n",
    "            count+=1\n",
    "    return count/len(x_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itUQnbiSvm8q"
   },
   "source": [
    "Leave_out evaluation for k=1, 3, 5, 7, 9, and 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Atvur_DciEeN",
    "outputId": "73371cc9-1e56-4bd3-d78d-8219b97c551b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of KNN for k= 1 : 55.00000000000001\n",
      "Accuracy score for Naive Bayes : 70.0\n",
      "Accuracy score of KNN for k= 3 : 61.66666666666667\n",
      "Accuracy score of KNN for k= 5 : 61.66666666666667\n",
      "Accuracy score of KNN for k= 7 : 60.83333333333333\n",
      "Accuracy score of KNN for k= 9 : 63.33333333333333\n",
      "Accuracy score of KNN for k= 11 : 59.166666666666664\n"
     ]
    }
   ],
   "source": [
    "knd = Knn(1)\n",
    "nav = GaussianNaiveBayes()\n",
    "print('Accuracy score of KNN for k= 1 :',leave_out(knd,x_train,y_train))\n",
    "print('Accuracy score for Naive Bayes :',leave_out(nav,x_train,y_train))\n",
    "knd = Knn(3)\n",
    "print('Accuracy score of KNN for k= 3 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(5)\n",
    "print('Accuracy score of KNN for k= 5 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(7)\n",
    "print('Accuracy score of KNN for k= 7 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(9)\n",
    "print('Accuracy score of KNN for k= 9 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(11)\n",
    "print('Accuracy score of KNN for k= 11 :',leave_out(knd,x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWWb4SxWv8f5",
    "outputId": "019e3a41-230b-4968-fdf8-ae707e11fb81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train =inpu[: , 0:2]#age data removed\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0r15Oh8AxYXm",
    "outputId": "768496c7-96a6-496e-896a-73b670c06c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of KNN for k= 1 : 62.5\n",
      "Accuracy score for Naive Bayes : 70.83333333333334\n",
      "Accuracy score of KNN for k= 3 : 70.83333333333334\n",
      "Accuracy score of KNN for k= 5 : 65.0\n",
      "Accuracy score of KNN for k= 7 : 63.33333333333333\n",
      "Accuracy score of KNN for k= 9 : 60.0\n",
      "Accuracy score of KNN for k= 11 : 57.49999999999999\n"
     ]
    }
   ],
   "source": [
    "knd = Knn(1)\n",
    "nav = GaussianNaiveBayes()\n",
    "print('Accuracy score of KNN for k= 1 :',leave_out(knd,x_train,y_train))\n",
    "\n",
    "print('Accuracy score for Naive Bayes :',leave_out(nav,x_train,y_train))\n",
    "knd = Knn(3)\n",
    "print('Accuracy score of KNN for k= 3 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(5)\n",
    "print('Accuracy score of KNN for k= 5 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(7)\n",
    "print('Accuracy score of KNN for k= 7 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(9)\n",
    "print('Accuracy score of KNN for k= 9 :',leave_out(knd,x_train,y_train))\n",
    "knd = Knn(11)\n",
    "print('Accuracy score of KNN for k= 11 :',leave_out(knd,x_train,y_train))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b72b662983f8bc6605c3403a16fdac79c5c8bbf730dded7b7d4c603d812e273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
